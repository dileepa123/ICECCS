\section{Explanation of the Algorithms}

\subsection{Algorithm 1}
In line $1$ the algorithm calculates the minimum value of the probabilities for all global transitions. The probability for one global transition is the product of each local probability. Since we calculate the minimum probability, we consider the case that all the non-Byzantine players are altruistic.\\
We estimated the sufficient number iterations ($iter$) for verification as follows (in line $2$). Before that $iter$ number of steps the termination probability has an upper bound which should be smaller than $\epsilon$ denoted as,
$(1-p_{min})^{iter} < \epsilon$. From the above formula $iter$ is derived as,
 $iter = \ceil{\frac{log(\epsilon)}{log(1-p_{min})}}$.\\
 From line $3$ to line $5$ if $iter > iter_{max}$ it means that the algorithm cannot make a decision within the maximum allowed iteration steps. Therefore it returns \textit{NOT DECIDED}. If $iter \le iter_{max}$ we call algorithm $2$ and store the returned value in \textit{Result} (line $6$). If the value is $\mi{TRY}\ \mi{SMALLER}\ \epsilon$ we call the algorithm $1$ by changing $\epsilon$ to $\frac{\epsilon}{2}$ (line $7$ to $8$). Otherwise, the returned value is a definite answer on whether the system is a Nash-equilibrium. Therefore, we report the returned value (line $10$).

\subsection{Algorithm 2}
For every non-Byzantine player $i$, we first calculate maximum absolute transition pay-off (line $4$), maximum absolute state pay-off (line $5$), minimum value of probability of global transition (line $6$). Note that we use $AH^r_i$ and $SH^r_i$ in line $4$ and $5$ respectively, because, $AH^r_i$ contains $AH^a_i$ ($SH^r_i$ contains $SH^a_i$) due to fact that rational player has more states and transitions.\\
In line $7$ and $8$, we calculate the upper bound of the size of range of uncertainty of the expected transition pay-off and state pay-off in $iter$ steps respectively. Then we initialize $V_i$, $U_i$, $Vl_i$ and $Ul_i$ to $0$ (line $9$ and $10$).\\
From  line $12$ to $16$ we update the four values iteratively by using a dynamic programming algorithm. For any global state $s$, $t^{th}$ iteration in the algorithm updates the optimized pay-offs that can be obtained in $t$ steps starting from the state $s$. For perfect information games, we do a pre-process to transfer each transition pay-off to the state pay-off that the transition leads to. Similarly, for imperfect information, we transfer each state pay-off to the transition pay-off that the transition leads to the state. 

In line $12$, for state $s$ in the $t^{th}$ iteration we first 1) add the pay-off from immediate transitions from $s$ to $s'$ to the corresponding optimal pay-offs calculated  at state $s'$ for $t-1$ steps (this value has been calculated at the previous iteration) and the result is denoted by $v$. Since, there can be many $s'$s that $s$ can transit to we actual have a set of values. We 2) group a set of $v$s by fixing the choice of Byzantine and rational players and calculate the expected value ($ev$) of this set denoted as $E_{s'_{Al \setminus \{i\}} \in S_{Al \setminus \{i\}}}$. Now we have a set of expected values each corresponding to a choice of Byzantine and rational players. We again 3) group a set of $ev$'s by fixing the rational choice and calculate the minimum of the set and call it $bev$. This means for any choice by the rational player, Byzantine player chooses his action such that the rational player's pay-off is minimized. Finally, we 4) find the maximum value of the set of $bevs$ and assign it to $V_i(s,t)$. This means rational player chooses his action such that his pay-off is maximised in this restricted set.\\
In line $13$, we calculate $U_i(s,t)$ which is the optimal expected pay-off of the altruistic player $i$ from the state $s$ after $t$ steps. The calculation is similar to the previous line. The only difference is that, in the final grouping step we calculate the expected value instead of the maximum value because, we are considering altruistic players which do not choose between actions but follow the probabilistic distribution.\\
Line $14$ is similar to line $12$. The differences are we use $AH_i^r$ instead of $SH_i^r$ and we add a step between 2) and 3) and denote the new step as 2'). In step 2'), since we are considering imperfect information games there is a set of equivalent global states for a given local state of player $i$ we have multiple sets of $bev$s. We need to calculate the expected value (denoted as $\{E_{\{s \in S | s_i=ls\}} $ ) for each set as the $bev$ for the final step.\\
Similarly, in line $15$ we add the additional step to line $13$ and calculate $Ul_i(s,t)$ using $AH_i^r$ instead of $SH_i^r$.\\

After updating the four values in $iter$ steps we can decide whether the system is Nash-Equilibrium. If the game is imperfect information, after $iter$ iterations for all altruistic players, if the $Vl_i(init,iter)$ -- optimal rational pay-off starting from the local initial state $init$ and playing for $iter$ steps -- is not larger than $Ul_i(init,iter)$ -- the altruistic pay-off-- and the difference between $Ul_i(init,iter)$ and $Vl_i(init,iter)$ is not smaller than $\mi{max}_{\mi{Aerror}}$ then the system is a Nash-equilibrium, thus the system returns \textit{PASS} (line $19$ and $20$). The conditions ensures that all the possible values for $Vl_i(init)$ are not larger than any possible value of $Ul_i(init)$. Therefore, any non-Byzantine player does not deviate from the protocol. Similarly,the conditions ensure that --add conditions-- $Vl_i(init)$ is larger than $Ul_i(init)$ for some $i$. This means that, a player may deviate from the protocol specification and thus the protocol is not a Nash-equilibrium (line $20$-$22$). The reasoning is similar for perfect information games (line $25$-$29$). If none of the above conditions are satisfied means that the error bound is too large i.e. the $iter$ is too small. In this case we return $\mi{TRY}\ \mi{SMALLER}\ \epsilon$. A smaller $\epsilon$ would lead to more iteration steps and lower $\mi{max}_{\mi{Aerror}}$ and $\mi{max}_{\mi{Serror}}$ which increases the probability of finding a definite answer. 


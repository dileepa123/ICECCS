

 
%$W_i^{t}(s)=\left\{\begin{array}{l}
%0\ \mbox{if}\ t=0\\
%E(SH_i(s')+W_i^{t-1}(s')| T(s,a)=s' \text{ for some a})\\
%\end{array}\right. $
% It is sufficient to prove that $|W_i^{t}(s)|$ is increasing w.r.t. $t$, $s \in S$ and $i \in [n]$ and $|W_i^{t}(s)|$ is bounded below by
%  $\frac{N \times max_s\{|SH_i(s)| \}}{p_{min}^{N}}$.



\section{Examples}\label{sec:ex}
It appears that the optimal move for a single iteration optimizes the expected pay-off in the long run. We have proved that for equal probability strategy, optimal moves for rational player and Byzantine player was the repetitive use of optimal move for each single iteration. For unequal probability strategy without Byzantine player we do not have to consider the optimal long-run strategy of a rational player to prove the Nash-equilibrium. (The reason is that optimal long-run expected pay-off for an altruistic player is $0$ irrespective of the strategy, and the rational player has a strategy which results in a positive pay-off for each iteration. It is logical that optimal strategy of the rational player also results in a positive expected pay-off. In order to arrive at this conclusion we do not explicitly generate the optimal rational strategy.)  When it comes to unequal probability strategy with Byzantine players, we need to calculate optimal strategies for rational players as well as altruistic players because, we do not have any logical inferencing to argue about the optimal long-run expected pay-offs without explicitly generating them. Now, the claim about repeating the move which optimized a single iteration to optimize the expected pay-off in the long-run, has become counter intuitive. We start by investigating the case where, we have unequal probability strategy with Byzantine player for a game having two iterations.\\
The analysis considers the case when $p_1$ is Byzantine, $p_2$ is rational and $p_3$ is altruistic. $p_1$,$p_2$ and $p_3$ are defined in section \ref{sec:casestudy}.
We define following $6$ symbols. $\gamma_0$, $\gamma_1$ and $\gamma_2$ are the restarting probabilities when $p_2$ plays rock , paper , scissor moves respectively. $X_0$, $X_1$ and $X_2$ are the expected pay-offs for $p_2$ , for rock , paper , scissor moves respectively.
$\gamma_0=\frac{4}{5}$, $\gamma_1=\frac{4}{5}$ and $\gamma_2=\frac{2}{5}$.\\
We show the calculation for $X_0$ here. 
Table \ref{tab:3} shows the pay-offs for a rational player in a single iteration when he plays rock. According to the table, expected pay-off for the first iteration is calculated as,\\
$\frac{1}{5}\times (-1) + \frac{1}{5}\times (-2) + \frac{3}{5}\times (-0) = \frac{-3}{5}$. Hence, $X_0=\frac{-3}{5}$. $X_1$ and $X_2$ are calculated in a similar way. The results are $X_1=\frac{-7}{5}$ and $X_2=-1$ respectively.\\
Consider two iterations, the expected pay-off for rational player $p_2$ in two iterations is calculated as, \\
$X_i+P_i\times X_j$ where $i,j \in \{0,1,2\}$. Since $\gamma_0=\gamma_1$ and $X_0 > X_1$, rock move is more optimal than paper move in both iterations. Hence, we consider only the rock move and the scissor move for the analysis. Now we have four strategies to compare. (two moves for the first iteration $\times$ two moves for the second iteration) For any given first move, the second move to optimize the summation would be the maximum between $X_0$ and $X_2$. Now we have only two strategies to compare.\\
\begin{itemize}
	\item $X_0+\gamma_0\times X_0= \frac{-3}{5} + \frac{4}{5}\times \frac{-3}{5}=-1.44 $\\
	\item $X_2+\gamma_1\times X_0= -1 + \frac{2}{5}\times \frac{-3}{5}=-1.24$
\end{itemize}
We can see that second strategy becomes optimal as instead of repetitive rock strategy. This counter intuitive result is caused by the restarting probability. In case of negative pay-offs, even though a move has high expected pay-off values in a single iteration, higher restarting probabilities make them less profitable in the long-run and vice-versa.\\
 We can deduce that the long-run optimal altruistic and rational strategies for an infinite number of iterations is not trivial. We show how to determine the optimal strategies in the long-run in our proof of Nash-equilibrium for the unequal strategy in Section \ref{sec:proofs}.
\section{Theorems and Proofs}\label{sec:proofs}

\begin{theorem}\label{thm: NE}
	Let $\mathcal{M}$ be a mechanism defined in section \ref{sec:ex}.
	Let $\pia(s^a_1, 0) = 1/5, \pia(s^a_1, 1)= 1/5, \pia(s^a_1, 2) = 3/5$. Suppose there is one Byzantine player. $\pia$ is a Nash-equilibrium
\end{theorem}

First we have to show that, rational players strategy is always playing the scissor move. 

We use the notation defined in section \ref{sec:ex} for the rest of the proof.
To calculate the expected pay-off for the rational player in the long-run, we have to define restarting probabilities and expected pay-offs w.r.t. each iteration. For the $i^{th}$ iteration there is a corresponding $X^{(i)}$ term and a $P^{(i)}$ term. $X^{(i)}$ is the expected pay-off at $i^{th}$ iteration. $X^{(i)}$ can take any value among $\{ X_0, X_1, X_2 \}$.\\ $P^{(i)}$ is the restarting probability at $i^{th}$ iteration. $P^{(i)}$ can take any value among $\{ \gamma_0, \gamma_1, \gamma_2 \}$. Since the restarting probability depends on the current move, $X^{(i)}$ and $P^{(i)}$ can be related. \\
$\forall$ $k \in$ $\{0,1,2\}$, $X^{(i)}=X_k \iff P^{(i)}=P_k $ 
Now we can define the weighted expected pay-off of the iteration $i$. Simply it should be the product of expected pay-off of the iteration $i$ and the probability of reaching iteration $i$.\\
Expected pay-off of the iteration $i$ is $X^{(i)}$. probability of reaching iteration $i$ is\\

$Pr(i)=\left\{\begin{array}{l}
1\ \mbox{if}\ i=1\\
\Pi_{k=1}^{i-1}P^{(k)} \ \mbox{if}\ i>1\\
\end{array}\right. $

The long run pay-off is the infinite summation of all the weighted expected pay-offs is,\\

$\Sigma_{i=1}^{\infty} X^{(i)}Pr(i)$.\\

\begin{lemma}\label{lem:conv}
	The series  $\Sigma_{i=1}^{\infty} X^{(i)}Pr(i)$ Converges.
\end{lemma}
\begin{proof}
	We can prove the absolute convergence of  the series which is sufficient to prove the convergence of the original series. \\
	$\Sigma_{i=1}^{\infty} |X^{(i)}Pr(i)|$\\
	$\impliedby \Sigma_{i=1}^{\infty} |X^{(i)}||Pr(i)|$ \\
	Let's consider the summation of $n$ terms in the series ($\Sigma_{i=1}^{n} |X^{(i)}||Pr(i)|$) as the $n^{th}$ term in a sequence. Then we have to prove the convergence of this sequence. According to  sequence convergence theorems we can prove that the sequence is increasing and bounded above. Increasing property is trivial because the series has absolute values.\\
	$|X^{(i)}| < c=max(\{ |X_0|, |X_1|, |X_2| \}) \forall$ $i$\\
	$|P^{(i)}| < q=max(\{ |\gamma_0|, |\gamma_1|, |\gamma_2| \}) \forall$ $i$\\
	$|Pr(i)| < q^{i-1} \forall$ $i$\\
	$\Sigma_{i=1}^{\infty} |X^{(i)}Pr(i)| \le \Sigma_{i=1}^{\infty} cq^{i-1}$\\
	The right hand side of the inequality shows an infinite geometric progression with the common-ratio $q$ and the initial term $c$. Since, $q < 1$ this series converges to $\frac{c}{1-q}$. \\
	$\Sigma_{i=1}^{\infty} |X^{(i)}Pr(i)| \le \frac{c}{1-q}$.\\
	$\Sigma_{i=1}^{n} |X^{(i)}Pr(i)| \le \frac{c}{1-q}$ $\forall n$. \\
	The sequence $\Sigma_{i=1}^{n} |X^{(i)}Pr(i)|$ is bounded above. Hence The series,\\
	$\Sigma_{i=1}^{\infty} |X^{(i)}Pr(i)|$ converges. The absolute convergence implies the convergence of the original series as well.
\end{proof}

\begin{proof}(Theorem \ref{thm: NE})
 
 
 Now we can proceed with our optimality proof. We first have a general strategy $Sr$ and $Sr=\Sigma_{i=1}^{\infty} X^{(i)}Pr(i)$. The value $Sr$ exists as a real number by lemma \ref{lem:conv}. For the sake of argument\\
 let  $\exists j $ s.t. $X^{(j)}=X_2$. Now define $Sr_0$ to be the long-run pay-off achieved by changing the scissor move at iteration $j$, to a rock move. Also define  $Sr_1$ to be the long-run pay-off achieved by changing the scissor move at iteration $j$ to a paper move. If we prove that $Sr_0-Sr<0$ and $Sr_1-Sr<0$ then it is evident that playing scissors at any iteration is optimal.\\
 
 \begin{itemize}
 	\item Case $1$: Proof of $Sr_0-Sr<0$\\
 	It is clear that terms in the both series appear before $j^{th}$ term cancels off when finding the difference. Let $j^{th}$ term of the series $Sr$ and $Sr_0$ are $Sr(j)$ and $Sr_0(j)$ respectively.\\
 	$Sr_0-Sr=\Sigma_{i=j}^{\infty} Sr_0(i) - Sr(i)$.\\
 	$Sr_0(j) - Sr(j)=Pr(j)(X_0-X_2)$. Let $M=\Sigma_{i=j+1}^{\infty}Sr(i)$. With the change of move in $j^{th}$ iteration, for every product $Pr(i), i > j$ $P^{j}$ is changed from $\gamma_2$ to $\gamma_0$. $\Sigma_{i=j+1}^{\infty}Sr_0(i)= \frac{\gamma_0}{\gamma_2}M$.\\
 	$\Sigma_{i=j+1}^{\infty} Sr_0(i) - Sr(i)=\frac{\gamma_0}{\gamma_2}M-M$.\\
 	$Sr_0-Sr=Pr(j)(X_0-X_2)+\frac{P_0}{P_2}M-M$.\\
 	Let's substitute the known values the expression,\\
 	$Pr(j)(\frac{-3}{5} - (-1))$ $+ \frac{\frac{4}{5}}{\frac{2}{5}}\times M - M$.\\
 	Now it is sufficient to prove that,
 	$Pr(j)\frac{2}{5} + M < 0$\\
 	$\impliedby |M| > Pr(j)\frac{2}{5}$. ($M < 0$)\\
 	By dividing both sides of the inequality by $Pr(j)$, Left hand side of the inequality becomes,\\
 	$M'=\Sigma_{i=j+1}^{\infty} (\Pi_{k=j}^{i-1}P^{(k)})X^{(i)}$ \\
 	$\impliedby |M'| > \frac{2}{5}$ . Now we find a lower bound for $M'$ and prove that it is always greater than $\frac{2}{5}$.  To find the lower bound we substitute the least absolute value among $\{X_0,X_1,X_2\}$ and $\{\gamma_0,\gamma_1,\gamma_2\}$ which would be  	$\frac{3}{5}$ and $\frac{2}{5}$ respectively to all the $X^{(i)}$'s and $P^{(i)}$'s. So, $M'$ reduces to the geometric progression,\\
 	$\frac{3}{5}(\frac{2}{5}+\frac{2}{5}^2+ \dots)$. Which converges to $\frac{2}{5}$. The finite summation for any number of terms in $|M'|$ is always $< \frac{2}{5}$. Now we can see that this lower bound is not sufficient to prove that $|M'| > \frac{2}{5}$ for sufficiently large number of terms in the series\\
 	However, we know that the above substituted values do not show an existing path for a rational player. To arrive at an existing path we have to change at least one substituted value of $X^{(i)}$'s or $P^{(i)}$'s. Let's say this substitution increases the converged value by $\epsilon$. According to series convergence theorems we can also find $\epsilon' < \epsilon$ s.t $|M'| > \frac{2}{5} - \epsilon'$ for a finite summation of sufficiently large number of terms. After the new substitution, $|M'|$ becomes $M''=|M'|+\epsilon$. (the convergence can be proven)\\
 	$|M'|+\epsilon > \frac{2}{5} - \epsilon' + \epsilon$ \\
 	$\implies M'' > \frac{2}{5}$ for a sufficiently large number of terms.\\
 	$\implies |M| > \frac{2}{5}$ for a sufficiently large number of terms.
 	\item Case $2$: Proof of $Sr_1-Sr<0$\\
 	After substitution Case $2$ reduces to prove that\\
 	$Sr_1-Sr=Pr(j)(X_1-X_2)+\frac{\gamma_1}{\gamma_2}M-M < 0$. Now let's substitute the values to the expression it is sufficient to prove that .\\
 	$Pr(j)(\frac{-2}{5}) + M < 0$ which is obvious because $M < 0$.
 \end{itemize}
 
 According to the best strategy of the rational player which is proven above, the optimal expected pay-off in the long-run for the rational player is $\frac{-5}{3}$.
 
 Now we can prove the best strategy for an altruistic player. In this scenario we have two altruistic players and one Byzantine player. We have to consider the pay-offs for each move of the Byzantine player. We are going to prove that Byzantine playing  rock at each iteration results in the worst outcome for an altruistic player. \\
 Values for $\gamma_0$ , $\gamma_1$ and $\gamma_2$ become $\frac{14}{25}$, $\frac{18}{25}$ and $\frac{18}{25}$ respectively. $X_0$ , $X_1$ and $X_2$ become $-0.4$, $0.4$ and $0$ respectively.\\
 Similar to the previous proof, we can name the general expression for the cumulative expected pay off in long-run as $Sr$. The expression results in modifying rock move to paper move and scissor move are named as $Sr_1$ and $Sr_2$ respectively. $Sr_1$ and $Sr_2$ also exist by lemma \ref{lem:conv}.
 What we have to prove is $Sr_1 - Sr > 0$ and $Sr_2 - Sr > 0$.\\
 
 \begin{itemize}
 	\item Case $1$: Proof of $Sr_1 - Sr > 0$
 	After similar simplification to previous proof, It is left to prove that\\
 	$0.8Pr(j) + \frac{4}{14}M > 0$. Here, each $Pr(j)$ and $M$ have same semantics to previous proof. If $M>0$ the result is trivial. We have to check the result only for the case where $M < 0$. We are going to find an upper bound for $|M|$ when $M<0$. This upper bound occurs when each term of $M$ is negative. For a term of $M$ to be negative, the rock strategy must be followed, because expected pay-offs of other two strategies are non-negative. To result in an upper bound each term in $M$ have to be bounded above. We bound each term of $M$ by substituting $X^{(i)}$ with $X_0=-0.4$ and substituting $P^{(i)}$ with $\frac{18}{25}$ which is the maximum among $\{ \gamma_0, \gamma_1, \gamma_2 \}$. After the substitution, and dividing both sides by $Pr(j)$ we have $M'= \frac{M}{Pr(j)}$\\
 	$|M'| = 0.4(\frac{18}{25}+\frac{18}{25}^2+ \dots)$ This converges to $\frac{36}{35}$. We have to prove that\\
 	$\frac{4}{14}|M'| < 0.8$.By substituting the value of $M'$ we get\\
 	$\frac{72}{245} < 0.8$ \\
 	$\implies 0.8Pr(j) + \frac{4}{14}|M| > 0 $.
 	
 	\item Case $2$: Proof of $Sr_2 - Sr > 0$
 	It is left to prove that $0.4Pr(j) + \frac{4}{14}M > 0$. We can use the same upper bound for $|M|$ as in Case $1$ and the proof reduces to proving,\\
 	$\frac{72}{245} < 0.4$.
 \end{itemize}
 
 The Byzantine player chooses the worst strategy for the altruistic player, which is proven above. The optimal expected pay-off in the long-run for the altruistic player is $\frac{-10}{11}$. \\
 Since $\frac{-10}{11} \ge \frac{-5}{3}$ the altruistic strategy $\langle \frac{1}{5},\frac{1}{5},\frac{3}{5} \rangle$ is a Nash-equilibrium when $p_1$ is Byzantine. 	
\end{proof}

 

 	
% 	We would add all $X^{i}$ s with $C=max(\{ |X_0|, |X_1|, |X_2| \})$ so the resulting series $Sr'$ becomes non negative. The new series is increasing and bounded above by
% 	$Sr' \le \frac{2C}{1-max(\{ P_0, P_1, P_2 \}) }$. Hence $Sr'$ converges.\\
% 	And now consider the series $C'=\Sigma_{i=1}^{\infty} C \times Pr(i)$. This series is also increasing and can be bounded above by $C' \le \frac{C}{1-max(\{ P_0, P_1, P_2 \}) }$. $C'$ also converges.\\
% 	Now $Sr=Sr'-C'$. Since each of $Sr'$ and $C'$ converges $Sr$ also converges.


   
 Now we can prove that the long-run expected pay-off $V_i(init,t)$ and $U_i(init,t)$ (notation in section \ref{sec:verification}) also converge. 
 Let $s^(1),s^(2) \dots$ denote the global state sequence visited during a game execution. If we fix a sequence of valid choices of actions by Byzantine and rational players we obtain a sub graph of the global graph. For example, a valid action choice sequence can be $\langle (rock,paper),(rock,paper),\dots, (rock,paper) \rangle$ where we have one Byzantine player and one rational player.
 
 \begin{defn}
 $Te=\{s | s \in S . \forall$  $a \in A$  $, \forall s' \in S$ $ T(s,a) \neq s' \}$
 \end{defn}
 
 Formally, if a game terminates, $P(\exists i s.t s^(i) \in Te) \rightarrow 1$. Following theorem introduces the condition in global state graph to assure $P(\exists i s.t s^(i) \in Te) \rightarrow 1$. This condition will also assure that the cumulative expected pay-off for any rational player converges.  \\


\begin{theorem}\label{thm:reach}
%	Consider the global graph of the Mechanism $\mathcal{M}$. Introduce an initial state $\hat{x}$ which has a directed transition to each initial state $\in I$. Introduce a terminal state $F$ which is one directed edge away from each of the terminal states.\\
%	If all the non-initial states can be reachable from the initial state $\hat{x}$ and  $F$ also can be reachable by non-terminal in the graph
If for any sequence of valid action choices of Byzantine and rational players,  the corresponding sub graph contains a path from each initial state to a terminal state then  \\
	$P(\exists i s.t s^(i) \in Te) \rightarrow 1$
\end{theorem}


%The reachability properties in the theorem \ref{thm:reach} can be verified by performing a depth first search, 
%\begin{enumerate}
%	\item From initial state $\hat{x}$  on graph $\mathcal{M}$
%	\item From final state $F$ on inverted graph of $\mathcal{M}$
%\end{enumerate}
%Inverted graph, refers to the graph obtained by inverting the edge directions of the original graph.

\begin{proof}(Theorem \ref{thm:reach})
 For a given sub graph corresponding to a sequence of valid action choices of Byzantine and rational players, there is a loop less longest path from an initial state to a terminal state.  Let $N$ be the length of longest of such paths among all the sub graphs corresponding to valid action choices . The minimum probability of reaching a terminal state occurs in the maximal length path. $N$ represents the length of this path. Let's name the minimal probability for a transition as $p_{min}>0$. The minimum probability exists because, the number of probabilistic transitions is finite. The probability of the given $N$ length path ($p_{min}^N$) is a lower bound for reaching any terminal state within $N$ steps. We can extend this to reaching any terminal state within $2N$ steps to $p_{min}^N(1+(1-p_{min}^N))$\\
Reaching a terminal state within $iN$ steps is\\ $p_{min}^N(\Sigma_{k=0}^{i-1}(1-p_{min}^N)^k)$ which becomes an infinite geometric series when $i$ tends to $\infty$. This converges to\\
 $p_{min}^N \times \frac{1}{1-(1-p_{min}^N)}= p_{min}^N \times \frac{1}{(p_{min}^N)}=1$. Since a series which is a lower bound to termination probability converges to probability $1$, and the total probability which is an upper bound to the termination probability converges to probability $1$. The actual termination probability also converges to probability $1$ by sandwich theorem.
\end{proof}


\begin{theorem}
	Let $i$ is an index for a non-Byzantine player according to section \ref{sec:spec}. Let $init \in I$. $V_i$ and $U_i$ are as defined in section \ref{sec:verification}.
	The sequences  $V_i(init,t)$ and $U_i(init,t)$ converge when $t \rightarrow \infty$.
\end{theorem}

\begin{proof}
	We first prove that, cumulative expected pay-off under valid choice of actions of Byzantine and rational players converge. We should write a general expression to represent the cumulative expected pay-off. We denote the global action for the $t^{th}$ step by the variable $x_t$. \\
	
	To visualize the strategy, we present a tree diagram. The tree diagram represents the reachable global states with the actions of the altruistic players when the actions of Byzantine players and rational players are fixed. Probabilities for each branch in the tree diagram are the product of probabilities for each altruistic action which lead to the resulting global state. In other words, branch probability is a joint probability. 
	
	\begin{forest}
		for tree={
			circle,
			draw,
			minimum height=1cm,
			anchor=north,
			align=center,
			child anchor=north
		},
		[{Start}, align=center, name=SS
		[{$S_1$}, name=st1
		[$S_3$, name=st3
		[$T$]
		[$S_6$]
		]
		[{$S_4$}
		[$S_7$]
		[$S_8$]
		]
		]
		[{$S_2$}, name=st2
		[$S_5$, name=st5
		[$S_9$]
		[$S_{10}$]
		]
		[{$T$}]
		]
		]
		%	\node[anchor=west,align=left] 
		%	at ([xshift=-2cm]MS.west) {Level 3\\Criteria};
		%	\node[anchor=west,align=left] 
		%	at ([xshift=-2cm]MS.west|-PDC) {Level 2\\ Group Criteria};
		%	\node[anchor=west,align=left] 
		%	at ([xshift=-2cm]MS.west|-SS) {Level 1\\Overall Objective};
	\end{forest}
	
	Node $Start$ is in level $0$, node $S_1$ and $S_2$ are in level $1$ and so on.
	In the above diagram, first level containing a terminal state is found $2$ steps steps after the starting state and one step after finding the first terminal state, second level containing the terminal state is found. Let's call $n_i$ is the difference (in levels) between $i^{th}$ level with a terminal state and $i-1^{th}$ level with a terminal state for $i>1$ $n_1$ is the level number of the first level containing a terminal state.\\
	Consider the minimum probability of reaching the first terminal state from the starting state which results in the maximum probability of the continuation of the game. Hence the maximum restarting probability after reaching the first terminal state is $(1-p_{min}^{n_1})$. Let $h_{max}= max_s |SH_k(s)|$. Cumulative pay-off value until the first level of termination can be bounded above by,\\
	$n_1 \times h_{max} \times (1-p_{min}^{n_1}) $ Cumulative pay-off value from the first level of termination to the second level of termination can be bounded above by,\\
	$n_2 \times h_{max} \times (1-p_{min}^{n_1})(1-p_{min}^{n_2}) $.\\
	Cumulative pay-off value from the $i-1 ^{th}$ level of termination to the $i^{th}$ level of termination can be bounded above by,\\
	$n_i \times h_{max} \times \Pi_{j=1}^{i} (1-p_{min}^{n_j}) $\\
	The formula for the upper bound of the cumulative pay-off value can be written as,\\
	$\Sigma_{i=1}^{\infty}(n_i \times h_{max} \times \Pi_{j=1}^{i} (1-p_{min}^{n_j})) $
	Since $n_i$, $n_j$ are strategy dependant, we substitute $N$ in the place of $n_i$ and $n_j$ to arrive at an upper bound which matches all the strategies.\\
	$\Sigma_{i=1}^{\infty}(N \times h_{max} \times (1-p_{min}^{N})^i) $\\
	By using the infinite summation for geometric series, the upper bound can be written as,\\
	$\frac{Nh_{max}}{p_{min}^{N}}$\\
	Note that, in the formula for a general strategy we have to substitute the exact expected pay-off value in the place of $n_i \times h_{max}$. We can see that by substituting $h_{max}$ we have also found out that the series for the absolute values of the pay-offs is also bounded above. \\
	Since the absolute pay-off series is a summation of positive values, the summation is an increasing function. This means absolute pay-off series is convergent which implies the actual pay-off series is also convergent.\\
	We proved above, cumulative expected pay-off for any altruistic strategy (Byzantines and rationals are fixed) converges in the long run. The values calculated for $V_i$ and $U_i$ should also converge.
\end{proof}

  